{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5aa67c75-08d0-413b-93c8-fc6f8dd566a2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Intelligent document processing with Gen AI, Amazon Textract and FlanT5 on SageMaker Jumpstart\n",
    "____\n",
    "\n",
    "\n",
    "In this notebook we will first use Amazon Textract's document extraction capabilities, and then the steps required to perform Q&A with a document first by extracting text from a document using Amazon Textract, generating chunks of text and store them into a Vector DB, and then performing Q&A with a FlanT5 model deployed in SageMaker endpoint via SageMaker Jumpstart and get precise answers from the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70342dd7-132e-4f71-b2a7-6311e7dab54c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Setup notebook <a id=\"step1\"></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b250172e-3298-4157-bf3e-0349d1e60536",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /opt/conda/lib/python3.10/site-packages (0.0.350)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages/PyYAML-6.0-py3.10-linux-x86_64.egg (from langchain) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.4.39)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (3.9.1)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.6.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.2 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.0.2)\n",
      "Requirement already satisfied: langchain-core<0.2,>=0.1 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.1.0)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.63 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.0.69)\n",
      "Requirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.26.0)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.10.11)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.1)\n",
      "Requirement already satisfied: anyio<5,>=3 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.2,>=0.1->langchain) (3.7.1)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.2,>=0.1->langchain) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (1.1.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1->langchain) (1.2.0)\n",
      "Requirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1->langchain) (1.1.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (0.4.3)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: pdfplumber in /opt/conda/lib/python3.10/site-packages (0.10.3)\n",
      "Requirement already satisfied: pdfminer.six==20221105 in /opt/conda/lib/python3.10/site-packages (from pdfplumber) (20221105)\n",
      "Requirement already satisfied: Pillow>=9.1 in /opt/conda/lib/python3.10/site-packages (from pdfplumber) (10.0.1)\n",
      "Requirement already satisfied: pypdfium2>=4.18.0 in /opt/conda/lib/python3.10/site-packages (from pdfplumber) (4.25.0)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from pdfminer.six==20221105->pdfplumber) (2.0.4)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in /opt/conda/lib/python3.10/site-packages (from pdfminer.six==20221105->pdfplumber) (41.0.4)\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.10/site-packages (from cryptography>=36.0.0->pdfminer.six==20221105->pdfplumber) (1.15.1)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20221105->pdfplumber) (2.21)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: unstructured in /opt/conda/lib/python3.10/site-packages (0.11.2)\n",
      "Requirement already satisfied: chardet in /opt/conda/lib/python3.10/site-packages (from unstructured) (4.0.0)\n",
      "Requirement already satisfied: filetype in /opt/conda/lib/python3.10/site-packages (from unstructured) (1.2.0)\n",
      "Requirement already satisfied: python-magic in /opt/conda/lib/python3.10/site-packages (from unstructured) (0.4.27)\n",
      "Requirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from unstructured) (4.9.3)\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from unstructured) (3.7)\n",
      "Requirement already satisfied: tabulate in /opt/conda/lib/python3.10/site-packages (from unstructured) (0.9.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from unstructured) (2.31.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from unstructured) (4.11.1)\n",
      "Requirement already satisfied: emoji in /opt/conda/lib/python3.10/site-packages (from unstructured) (2.9.0)\n",
      "Requirement already satisfied: dataclasses-json in /opt/conda/lib/python3.10/site-packages (from unstructured) (0.6.3)\n",
      "Requirement already satisfied: python-iso639 in /opt/conda/lib/python3.10/site-packages (from unstructured) (2023.12.11)\n",
      "Requirement already satisfied: langdetect in /opt/conda/lib/python3.10/site-packages (from unstructured) (1.0.9)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from unstructured) (1.26.0)\n",
      "Requirement already satisfied: rapidfuzz in /opt/conda/lib/python3.10/site-packages (from unstructured) (3.5.2)\n",
      "Requirement already satisfied: backoff in /opt/conda/lib/python3.10/site-packages (from unstructured) (2.2.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from unstructured) (4.9.0)\n",
      "Requirement already satisfied: wrapt in /opt/conda/lib/python3.10/site-packages (from unstructured) (1.14.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->unstructured) (2.3.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json->unstructured) (3.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json->unstructured) (0.9.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from langdetect->unstructured) (1.16.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk->unstructured) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk->unstructured) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.10/site-packages (from nltk->unstructured) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from nltk->unstructured) (4.66.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->unstructured) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->unstructured) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->unstructured) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->unstructured) (2023.7.22)\n",
      "Requirement already satisfied: packaging>=17.0 in /opt/conda/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->unstructured) (23.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->unstructured) (0.4.3)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: chromadb in /opt/conda/lib/python3.10/site-packages (0.4.18)\n",
      "Requirement already satisfied: requests>=2.28 in /opt/conda/lib/python3.10/site-packages (from chromadb) (2.31.0)\n",
      "Requirement already satisfied: pydantic>=1.9 in /opt/conda/lib/python3.10/site-packages (from chromadb) (1.10.11)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.3 in /opt/conda/lib/python3.10/site-packages (from chromadb) (0.7.3)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in /opt/conda/lib/python3.10/site-packages (from chromadb) (0.105.0)\n",
      "Requirement already satisfied: uvicorn[standard]>=0.18.3 in /opt/conda/lib/python3.10/site-packages (from chromadb) (0.24.0.post1)\n",
      "Requirement already satisfied: posthog>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from chromadb) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /opt/conda/lib/python3.10/site-packages (from chromadb) (4.9.0)\n",
      "Requirement already satisfied: pulsar-client>=3.1.0 in /opt/conda/lib/python3.10/site-packages (from chromadb) (3.3.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /opt/conda/lib/python3.10/site-packages (from chromadb) (1.16.3)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from chromadb) (1.21.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from chromadb) (1.21.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /opt/conda/lib/python3.10/site-packages (from chromadb) (0.42b0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from chromadb) (1.21.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /opt/conda/lib/python3.10/site-packages (from chromadb) (0.15.0)\n",
      "Requirement already satisfied: pypika>=0.48.9 in /opt/conda/lib/python3.10/site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /opt/conda/lib/python3.10/site-packages (from chromadb) (4.66.1)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /opt/conda/lib/python3.10/site-packages (from chromadb) (7.4.0)\n",
      "Requirement already satisfied: importlib-resources in /opt/conda/lib/python3.10/site-packages (from chromadb) (6.1.1)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /opt/conda/lib/python3.10/site-packages (from chromadb) (1.60.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from chromadb) (4.1.1)\n",
      "Requirement already satisfied: typer>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from chromadb) (0.9.0)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in /opt/conda/lib/python3.10/site-packages (from chromadb) (28.1.0)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in /opt/conda/lib/python3.10/site-packages (from chromadb) (8.2.3)\n",
      "Requirement already satisfied: PyYAML>=6.0.0 in /opt/conda/lib/python3.10/site-packages/PyYAML-6.0-py3.10-linux-x86_64.egg (from chromadb) (6.0)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from chromadb) (4.0.1)\n",
      "Requirement already satisfied: numpy>=1.22.5 in /opt/conda/lib/python3.10/site-packages (from chromadb) (1.26.0)\n",
      "Requirement already satisfied: anyio<4.0.0,>=3.7.1 in /opt/conda/lib/python3.10/site-packages (from fastapi>=0.95.2->chromadb) (3.7.1)\n",
      "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in /opt/conda/lib/python3.10/site-packages (from fastapi>=0.95.2->chromadb) (0.27.0)\n",
      "Requirement already satisfied: certifi>=14.05.14 in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (2023.7.22)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (2.25.2)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (0.58.0)\n",
      "Requirement already satisfied: requests-oauthlib in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
      "Requirement already satisfied: urllib3<2.0,>=1.24.2 in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (1.26.18)\n",
      "Requirement already satisfied: coloredlogs in /opt/conda/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /opt/conda/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (23.5.26)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (23.2)\n",
      "Requirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (4.24.4)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (1.10.1)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.14)\n",
      "Requirement already satisfied: importlib-metadata<7.0,>=6.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-api>=1.2.0->chromadb) (6.11.0)\n",
      "Requirement already satisfied: backoff<3.0.0,>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.62.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.21.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.21.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.21.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.21.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.42b0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.42b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.42b0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.42b0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.42b0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.42b0)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.42b0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.42b0)\n",
      "Requirement already satisfied: setuptools>=16.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-instrumentation==0.42b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (68.2.2)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-instrumentation==0.42b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.14.1)\n",
      "Requirement already satisfied: asgiref~=3.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-instrumentation-asgi==0.42b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.7.2)\n",
      "Requirement already satisfied: monotonic>=1.5 in /opt/conda/lib/python3.10/site-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.28->chromadb) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.28->chromadb) (3.3)\n",
      "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /opt/conda/lib/python3.10/site-packages (from tokenizers>=0.13.2->chromadb) (0.19.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.10/site-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
      "Requirement already satisfied: h11>=0.8 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.14.0)\n",
      "Requirement already satisfied: httptools>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.1)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.0)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.19.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
      "Requirement already satisfied: websockets>=10.4 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (12.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio<4.0.0,>=3.7.1->fastapi>=0.95.2->chromadb) (1.2.0)\n",
      "Requirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from anyio<4.0.0,>=3.7.1->fastapi>=0.95.2->chromadb) (1.1.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.7.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.6.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2023.12.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata<7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.8.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /opt/conda/lib/python3.10/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.8)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: sentence-transformers in /opt/conda/lib/python3.10/site-packages (2.2.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.36.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.66.1)\n",
      "Requirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (2.1.1)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.16.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.26.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.0.1)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.11.3)\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (3.7)\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.1.99)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.19.4)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2023.12.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.31.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages/PyYAML-6.0-py3.10-linux-x86_64.egg (from huggingface-hub>=0.4.0->sentence-transformers) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (23.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (1.10.1)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.6.0->sentence-transformers) (12.3.101)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2022.7.9)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.15.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.4.1)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk->sentence-transformers) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk->sentence-transformers) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (2.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->sentence-transformers) (10.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: pydantic==1.10.11 in /opt/conda/lib/python3.10/site-packages (1.10.11)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from pydantic==1.10.11) (4.9.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "amazon-textract-prettyprinter 0.1.8 requires amazon-textract-response-parser<0.2,>=0.1, but you have amazon-textract-response-parser 1.0.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -U langchain \n",
    "!pip install pdfplumber\n",
    "!pip install unstructured\n",
    "!pip install chromadb\n",
    "!pip install -U sentence-transformers\n",
    "!pip install pydantic==1.10.11 #use 1.10.11 version due to stability\n",
    "#textractor libraries\n",
    "!python -m pip install -q amazon-textract-caller --upgrade\n",
    "!python -m pip install -q amazon-textract-prettyprinter --upgrade\n",
    "!python -m pip install -q amazon-textract-response-parser --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3f2a96-7efb-4eab-8e52-93583fae0afb",
   "metadata": {},
   "source": [
    "# Module 1 - Document Extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4586ad84-849d-4078-b993-2d063fb9bcce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n",
      "Region is us-east-1, IAM Role: arn:aws:iam::768517646540:role/idp-SageMakerExecutionRole-Ir1Yes3jcOAq, S3 Bucket: sagemaker-us-east-1-768517646540\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import botocore\n",
    "import sagemaker\n",
    "from sagemaker.session import Session\n",
    "from sagemaker.session import Session\n",
    "from IPython.display import Image, display, JSON\n",
    "from textractcaller.t_call import call_textract, Textract_Features, call_textract_expense\n",
    "from textractprettyprinter.t_pretty_print import convert_table_to_list\n",
    "from trp import Document\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# variables\n",
    "sagemaker_session = Session()\n",
    "data_bucket = sagemaker.Session().default_bucket()\n",
    "region = boto3.session.Session().region_name\n",
    "aws_role = sagemaker_session.get_caller_identity_arn()\n",
    "\n",
    "# boto3 clients\n",
    "s3=boto3.client('s3')\n",
    "textract = boto3.client('textract', region_name=region)\n",
    "\n",
    "print(f\"Region is {region}, IAM Role: {aws_role}, S3 Bucket: {data_bucket}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1116bdef-fdf8-490b-ae57-a5dd8ded896f",
   "metadata": {},
   "source": [
    "## Upload sample data to S3 bucket\n",
    "\n",
    "\n",
    "The sample document is in `/samples` directory. For this workshop, we will be using a sample document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "99c5ba3c-a1be-423c-8866-5f0a01386125",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Upload images to S3 bucket:\n",
    "\n",
    "!aws s3 cp samples s3://{data_bucket}/idp/genai --recursive --only-show-errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6ddc56-cc4c-4b19-b770-451bacf4a6ac",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "# Extract structured data such as tables and key-value pairs using Amazon Textract\n",
    "\n",
    "\n",
    "### Extracting Tables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56706bf7-ae61-4c50-bd1d-41a4f552330b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prefix = \"idp/genai\"\n",
    "file_key = \"health_plan.pdf\"\n",
    "resp = call_textract(input_document=f's3://{data_bucket}/{prefix}/{file_key}', features=[Textract_Features.TABLES])\n",
    "tdoc = Document(resp)\n",
    "dfs = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97a9239b-8000-4ad2-ab93-af955c1c7354",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['PLAN INFORMATION Plan Name ', 'ANYCOMPANY INC '], ['Name And Address Of Employer ', 'ANYCOMPANY, INC 123 ANY STREET ANY CITY CA, 92127 '], ['Name, Address, And Phone Number Of Plan Administrator ', 'ANYCOMPANY, INC 123 ANY STREET ANY CITY CA, 92127 '], ['866-648-0044 ', ''], ['Named Fiduciary ', 'ANYCOMPANY, INC. '], ['Claims Appeal Fiduciary For Medical Claims ', 'UMR '], ['Employer Identification Number Assigned By The IRS ', '12-34567890 '], ['Plan Number Assigned By The Plan ', '511 '], ['Type Of Benefit Plan Provided ', 'Self-funded Health and Welfare Plan providing group health benefits. ']]\n",
      "[['Type Of Administration ', 'The administration of the Plan is under the supervision of the Plan Administrator. The Plan is not financed by an insurance company and benefits are not guaranteed by a contract of insurance. '], ['Name And Address Of Agent For Service Of Legal Process ', 'ANYCOMPANY, INC 123 ANY STREET ANY CITY CA, 92127 '], ['Funding Of The Plan ', 'Employer and Employee Contributions Benefits are provided by a benefit Plan maintained on a self-insured basis by Your employer. '], ['Benefit Plan Year ', \"Benefits begin on January 1 and end on the following December 31. For new Employees and Dependents, a Benefit Plan Year begins on the individual's Effective Date and runs through December 31 of the same Benefit Plan Year. \"], ['Plan Year ', 'January 1 through December 31 '], ['And Other Federal Compliance ', 'It is intended that this Plan comply with all applicable requirements of ABC and other federal regulations. In the event of any conflict between this Plan and ABC or other federal regulations, the provisions of ABC and the federal regulations will be deemed controlling, and any conflicting part of this Plan will be deemed superseded to the extent of the conflict. ']]\n"
     ]
    }
   ],
   "source": [
    "for page in tdoc.pages:\n",
    "    for table in page.tables:\n",
    "        tab_list = convert_table_to_list(trp_table=table)\n",
    "        print(tab_list)\n",
    "        dfs.append(pd.DataFrame(tab_list))\n",
    "df1 = dfs[0]\n",
    "df2 = dfs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1bfff420-d4ee-482a-91ad-fd1646e0c14c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PLAN INFORMATION Plan Name</td>\n",
       "      <td>ANYCOMPANY INC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Name And Address Of Employer</td>\n",
       "      <td>ANYCOMPANY, INC 123 ANY STREET ANY CITY CA, 92...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Name, Address, And Phone Number Of Plan Admini...</td>\n",
       "      <td>ANYCOMPANY, INC 123 ANY STREET ANY CITY CA, 92...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>866-648-0044</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Named Fiduciary</td>\n",
       "      <td>ANYCOMPANY, INC.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Claims Appeal Fiduciary For Medical Claims</td>\n",
       "      <td>UMR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Employer Identification Number Assigned By The...</td>\n",
       "      <td>12-34567890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Plan Number Assigned By The Plan</td>\n",
       "      <td>511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Type Of Benefit Plan Provided</td>\n",
       "      <td>Self-funded Health and Welfare Plan providing ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  \\\n",
       "0                        PLAN INFORMATION Plan Name    \n",
       "1                      Name And Address Of Employer    \n",
       "2  Name, Address, And Phone Number Of Plan Admini...   \n",
       "3                                      866-648-0044    \n",
       "4                                   Named Fiduciary    \n",
       "5        Claims Appeal Fiduciary For Medical Claims    \n",
       "6  Employer Identification Number Assigned By The...   \n",
       "7                  Plan Number Assigned By The Plan    \n",
       "8                     Type Of Benefit Plan Provided    \n",
       "\n",
       "                                                   1  \n",
       "0                                    ANYCOMPANY INC   \n",
       "1  ANYCOMPANY, INC 123 ANY STREET ANY CITY CA, 92...  \n",
       "2  ANYCOMPANY, INC 123 ANY STREET ANY CITY CA, 92...  \n",
       "3                                                     \n",
       "4                                  ANYCOMPANY, INC.   \n",
       "5                                               UMR   \n",
       "6                                       12-34567890   \n",
       "7                                               511   \n",
       "8  Self-funded Health and Welfare Plan providing ...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c253f5b-dd6b-4314-bc94-db266c675e6f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Type Of Administration</td>\n",
       "      <td>The administration of the Plan is under the su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Name And Address Of Agent For Service Of Legal...</td>\n",
       "      <td>ANYCOMPANY, INC 123 ANY STREET ANY CITY CA, 92...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Funding Of The Plan</td>\n",
       "      <td>Employer and Employee Contributions Benefits a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Benefit Plan Year</td>\n",
       "      <td>Benefits begin on January 1 and end on the fol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Plan Year</td>\n",
       "      <td>January 1 through December 31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>And Other Federal Compliance</td>\n",
       "      <td>It is intended that this Plan comply with all ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  \\\n",
       "0                            Type Of Administration    \n",
       "1  Name And Address Of Agent For Service Of Legal...   \n",
       "2                               Funding Of The Plan    \n",
       "3                                 Benefit Plan Year    \n",
       "4                                         Plan Year    \n",
       "5                      And Other Federal Compliance    \n",
       "\n",
       "                                                   1  \n",
       "0  The administration of the Plan is under the su...  \n",
       "1  ANYCOMPANY, INC 123 ANY STREET ANY CITY CA, 92...  \n",
       "2  Employer and Employee Contributions Benefits a...  \n",
       "3  Benefits begin on January 1 and end on the fol...  \n",
       "4                     January 1 through December 31   \n",
       "5  It is intended that this Plan comply with all ...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b8cebe-50a8-4574-90cf-8f578a862eab",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Extracting Forms (key-value pairs) data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "61e0ac8a-bff1-4845-8bdb-cc6d0330c2f8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key,Value\n",
      "3.,\"Improve population health. Invest in public health programs and prevention to promote healthy lifestyles, reduce health risks, and improve health outcomes.\"\n",
      "Policy Reforms:,3. Require insurance companies to cover pre-existing premiums due to health status. 4. Increase healthcare subsidies and tax credits. Make income individuals and families. 5. Invest in preventive care and public health. Increase\n",
      "Goals:,\n",
      "Revised,01-01-2022\n",
      "Mission:,\"To implement policy reforms and programs that expand access to healthcare, reduce costs, and improve health outcomes.\"\n",
      "Vision:,\"To provide high quality, affordable healthcare for all citizens.\"\n",
      "Key,Value\n",
      "Plan Name,ANYCOMPANY INC\n",
      "Claims Appeal Fiduciary For Medical Claims,UMR\n",
      "Name And Address Of Employer,\"ANYCOMPANY, INC 123 ANY STREET ANY CITY CA, 92127\"\n",
      "Type Of Benefit Plan Provided,Self-funded Health and Welfare Plan providing group health benefits.\n",
      "Plan Number Assigned By The Plan,511\n",
      "Employer Identification Number Assigned By The IRS,12-34567890\n",
      "\"Name, Address, And Phone Number Of Plan Administrator\",\"ANYCOMPANY, INC 123 ANY STREET ANY CITY CA, 92127\"\n",
      "Named Fiduciary,\"ANYCOMPANY, INC.\"\n",
      "Key,Value\n",
      "Benefit Plan,\n",
      "Type Of Administration Name And Address Of Legal Process Funding Of The Plan,\n",
      "Agent For Service Of,\"ANYCOMPANY, INC 123 ANY STREET ANY CITY CA, 92127\"\n",
      "Key,Value\n",
      "CO-PAYS,A Co-pay is the amount that the Covered Person pays each time certain services are received. The Co- pay is typically a flat dollar amount and is paid at the time of service or when billed by the provider. Co- pays do not apply toward satisfaction of Deductibles. Co-pays apply toward satisfaction of in-network and out-of-network out-of-pocket maximums. The Co-pay and out-of-pocket maximum are shown on the Schedule of Benefits.\n",
      "DEDUCTIBLES,\"A Deductible is an amount of money paid once per Plan Year by the Covered Person before any Covered Expenses are paid by this Plan. A Deductible applies to each Covered Person up to a family Deductible limit. When a new Plan Year begins, a new Deductible must be satisfied. Deductible amounts are shown on the Schedule of Benefits. Pharmacy expenses do not count toward meeting the Deductible of this Plan. The Deductible amounts that the Covered Person Incurs for Covered Expenses will be used to satisfy the Deductible(s) shown on the Schedule of Benefits. The Deductible amounts that the Covered Person Incurs at an in-network provider will apply to the in- network total individual and family Deductible. The Deductible amounts that the Covered Person Incurs at an out-of-network provider will apply to the out-of-network total individual and family Deductible.\"\n",
      "Note:,\"Embedded Deductible Means That If You Have Family Coverage, Any Combination Of Covered Family Members May Help Meet The Maximum However, No One Person Will Pay More Than His Or Her Embedded Individual Deductible Amount.\"\n",
      "Benefit Plan(s),\"001, 002, 005\"\n",
      "The following will not be used to meet the out-of-pocket maximums:,\"_Penalties, legal fees and interest charged by a provider. Any amounts over the Recognized Amount, Usual and Customary amount, Negotiated Rate or established fee schedule that this Plan pays.\"\n",
      "Family Deductible;,\n",
      "Key,Value\n",
      "NO FORGIVENESS OF OUT-OF-POCKET EXPENSES,\"The Covered Person is required to pay the out-of-pocket expenses (including Deductibles, Co-pays or required Plan Participation) under the terms of this Plan. The requirement that You and Your Dependent(s) pay the applicable out-of-pocket expenses cannot be waived by a provider under any \"\"fee forgiveness\"\", \"\"not out-of-pocket\"\" or similar arrangement. If a provider waives the required out-of-pocket expenses, the Covered Person's claim may be denied and the Covered Person will be responsible for payment of the entire claim. The claim(s) may be reconsidered if the Covered Person provides satisfactory proof that he or she paid the out-of-pocket expenses under the terms of this Plan.\"\n",
      "Benefit Plan(s),\"003, 004\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from textractcaller.t_call import call_textract, Textract_Features\n",
    "from textractprettyprinter.t_pretty_print import Pretty_Print_Table_Format, Textract_Pretty_Print, get_string\n",
    "\n",
    "\n",
    "# Call Amazon Textract\n",
    "response = call_textract(input_document=f's3://{data_bucket}/{prefix}/{file_key}', features=[Textract_Features.FORMS])\n",
    "\n",
    "\n",
    "print(get_string(textract_json=response,\n",
    "               table_format=Pretty_Print_Table_Format.csv,\n",
    "               output_type=[Textract_Pretty_Print.FORMS]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1efd28f-8fc3-4613-a6b8-25d41c24ba7b",
   "metadata": {},
   "source": [
    "# Module 2 - Enhancing IDP with Foundation Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a435b72c-988c-4e0c-9a12-9996889e01b4",
   "metadata": {},
   "source": [
    "## Select a pre-trained model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fbf51554-c002-4c6e-a0b3-a1490dd46ff9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# \"huggingface-text2text-flan-t5-xl\",\n",
    "# \"huggingface-text2text-flan-t5-large\",\n",
    "\n",
    "model_id, model_version, = (\n",
    "    \"huggingface-text2text-flan-t5-xl\",\n",
    "    \"2.0.0\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3916715b-cef5-4ad9-bc2b-3b897b54889d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Retrieve Artifacts & Deploy a HuggingFace FLAN-T5 Endpoint\n",
    "\n",
    "---\n",
    "\n",
    "Using SageMaker, we can perform inference on the pre-trained model, even without fine-tuning it first on a new dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b67f4200-5d12-4396-93fe-1f31f8eefdf3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_sagemaker_session(local_download_dir) -> sagemaker.Session:\n",
    "    \"\"\"Return the SageMaker session.\"\"\"\n",
    "\n",
    "    sagemaker_client = boto3.client(\n",
    "        service_name=\"sagemaker\", region_name=boto3.Session().region_name\n",
    "    )\n",
    "\n",
    "    session_settings = sagemaker.session_settings.SessionSettings(\n",
    "        local_download_dir=local_download_dir\n",
    "    )\n",
    "\n",
    "    # the unit test will ensure you do not commit this change\n",
    "    session = sagemaker.session.Session(\n",
    "        sagemaker_client=sagemaker_client, settings=session_settings\n",
    "    )\n",
    "\n",
    "    return session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ae79c1-b2eb-47a1-ba5e-fa7205941511",
   "metadata": {},
   "source": [
    "Deploy model as inference point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "25398a0e-194b-4df1-bfac-d347eff859ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n",
      "-----------!"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker.huggingface import HuggingFaceModel, get_huggingface_llm_image_uri\n",
    "from sagemaker.utils import name_from_base\n",
    "import config\n",
    "\n",
    "# Hub Model configuration. https://huggingface.co/models\n",
    "hub = {\n",
    "\t'HF_MODEL_ID':'google/flan-t5-xl',\n",
    "\t'SM_NUM_GPUS': json.dumps(1)\n",
    "}\n",
    "\n",
    "endpoint_name = name_from_base(f\"{config.SOLUTION_PREFIX}-{model_id}\")\n",
    "\n",
    "\n",
    "# create Hugging Face Model Class\n",
    "huggingface_model = HuggingFaceModel(\n",
    "\timage_uri=get_huggingface_llm_image_uri(\"huggingface\",version=\"1.1.0\"),\n",
    "\tenv=hub,\n",
    "\trole=aws_role, \n",
    ")\n",
    "\n",
    "# deploy model to SageMaker Inference\n",
    "predictor = huggingface_model.deploy(\n",
    "\tinitial_instance_count=1,\n",
    "\tinstance_type=\"ml.g5.2xlarge\",\n",
    "\tcontainer_startup_health_check_timeout=300,\n",
    "    name=endpoint_name\n",
    "  )\n",
    "  \n",
    "\n",
    "\n",
    "# from sagemaker import image_uris, model_uris, script_uris, hyperparameters\n",
    "# from sagemaker.model import Model\n",
    "# from sagemaker.predictor import Predictor\n",
    "# from sagemaker.utils import name_from_base\n",
    "# import config\n",
    "\n",
    "\n",
    "# endpoint_name = name_from_base(f\"{config.SOLUTION_PREFIX}-{model_id}\")\n",
    "\n",
    "# inference_instance_type = \"ml.g5.2xlarge\"\n",
    "\n",
    "# # Retrieve the inference docker container uri. This is the base HuggingFace container image for the default model above.\n",
    "# deploy_image_uri = image_uris.retrieve(\n",
    "#     region=None,\n",
    "#     framework=None,  # automatically inferred from model_id\n",
    "#     image_scope=\"inference\",\n",
    "#     model_id=model_id,\n",
    "#     model_version=model_version,\n",
    "#     instance_type=inference_instance_type,\n",
    "# )\n",
    "\n",
    "# # Retrieve the inference script uri. This includes all dependencies and scripts for model loading, inference handling etc.\n",
    "# deploy_source_uri = script_uris.retrieve(\n",
    "#     model_id=model_id, model_version=model_version, script_scope=\"inference\"\n",
    "# )\n",
    "\n",
    "\n",
    "# # Retrieve the model uri.\n",
    "# model_uri = model_uris.retrieve(\n",
    "#     model_id=model_id, model_version=model_version, model_scope=\"inference\"\n",
    "# )\n",
    "\n",
    "# #Create model\n",
    "# model = Model(\n",
    "#     image_uri=deploy_image_uri,\n",
    "#     model_data=model_uri,\n",
    "#     role=aws_role,\n",
    "#     predictor_cls=Predictor,\n",
    "#     name=endpoint_name,\n",
    "# )\n",
    "\n",
    "# # deploy the Model. Note that we need to pass Predictor class when we deploy model through Model class,\n",
    "# # for being able to run inference through the sagemaker API.\n",
    "# model_predictor = model.deploy(\n",
    "#     initial_instance_count=1,\n",
    "#     instance_type=inference_instance_type,\n",
    "#     predictor_cls=Predictor,\n",
    "#     endpoint_name=endpoint_name,\n",
    "#     # volume_size=30,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f09b09-f226-4a7b-ad2e-faecc5f42da4",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "# Perform Common sense reasoning and QA on a document\n",
    "\n",
    "In this section, we will perform common sense reasoning and Q&A on a document. This section does the following\n",
    "\n",
    "- Generates text from documents and stores them into S3 in plaintext format\n",
    "- Generate embeddings from the text\n",
    "- Uses an in-memory vector database to store the embeddings\n",
    "- Perform similarity search on the in-memory vector db to find relevant pieces of text that have relavancy to the asked question (by the user)\n",
    "- Generate the context for the LLM using the search results\n",
    "- Give the model the context and the original question asked\n",
    "- Get the answer back from the LLM\n",
    "- Profit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "180caa55-58c5-4672-807c-f0bb67af4a0a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sagemaker-us-east-1-768517646540'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3c52238b-282b-4498-bf25-945724196a0e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n",
      "Bucket is sagemaker-us-east-1-768517646540\n",
      "Page text written into llm/sample/page-1.txt\n"
     ]
    }
   ],
   "source": [
    "from textractcaller.t_call import call_textract, Textract_Features\n",
    "from trp.trp2 import TDocument, TDocumentSchema\n",
    "from trp.t_pipeline import order_blocks_by_geo\n",
    "import boto3\n",
    "import sagemaker\n",
    "import pdfplumber\n",
    "import mimetypes\n",
    "import trp\n",
    "import json\n",
    "import uuid\n",
    "\n",
    "\n",
    "\n",
    "data_bucket = sagemaker.Session().default_bucket()\n",
    "prefix=\"idp/genai\"\n",
    "file_key='discharge-summary.png'\n",
    "doc_path = f's3://{data_bucket}/{prefix}/discharge-summary.png'\n",
    "\n",
    "s3=boto3.client('s3')\n",
    "doc_text=list()\n",
    "page_num=1\n",
    "prefix=str(uuid.uuid4())\n",
    "\n",
    "print(f\"Bucket is {data_bucket}\")\n",
    "\n",
    "if not doc_text:\n",
    "    # CAREFUL: this only works with Single pages of scanned PDF documents\n",
    "    # typically we will have OCR done on the page in advance of the lang chain initiation\n",
    "    j = call_textract(input_document=doc_path) \n",
    "\n",
    "    t_doc = TDocumentSchema().load(j)\n",
    "    ordered_doc = order_blocks_by_geo(t_doc) #sort by reading order\n",
    "    trp_doc = trp.Document(TDocumentSchema().dump(ordered_doc))\n",
    "\n",
    "    doc_content = str()\n",
    "    # Iterate over elements in the document\n",
    "    for page in trp_doc.pages:\n",
    "        # Print lines and words\n",
    "        for line in page.lines:\n",
    "            doc_content = doc_content + \"\\n\" + line.text\n",
    "            \n",
    "        content_res = bytes(doc_content, 'utf-8')\n",
    "        s3.put_object(Bucket=data_bucket,\n",
    "                                Key=f\"llm/sample/page-{page_num}.txt\",\n",
    "                                Body=content_res)\n",
    "        print(f\"Page text written into llm/sample/page-{page_num}.txt\")\n",
    "        page_num=page_num+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "09069c6e-aedb-45dc-ac99-2dcb48ea979f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import S3DirectoryLoader\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import NLTKTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.schema import Document\n",
    "import sagemaker\n",
    "\n",
    "data_bucket = sagemaker.Session().default_bucket()\n",
    "prefix='llm/sample'\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings()\n",
    "loader = S3DirectoryLoader(data_bucket, prefix=prefix)\n",
    "docs = loader.load()\n",
    "text_splitter = NLTKTextSplitter(chunk_size=550)\n",
    "texts = text_splitter.split_documents(docs)\n",
    "vectordb = Chroma.from_documents(texts, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "639f01ec-07d8-4e8a-8fdc-84d12a7ca1e0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"Not a Memorial Hospital\\n\\nOf Collier\\n\\nReg: PN/S/11011, Non-Profit\\n\\nContact: (999)-(888)-(1234)\\n\\nPhysician Hospital Discharge Summary\\n\\nProvider: Mateo Jackson, Phd\\n\\nProvider's Pt ID: 00988277891\\n\\nPatient Gender: Male\\n\\nPatient: John Doe\\n\\nAttachment Control Number: XA/7B/00338763\\n\\nVisit (Encounter)\\n\\nAdmitted: 07-Sep-2020\\n\\nDischarged: 08-Sep-2020\\n\\nDischarged to: Home with support services\\n\\nAssessment\\n\\n35 yo M c/o stomach problems since 2 montsh ago. Patient\\n\\nReported Symptoms / History\\n\\nreports epigastric abdominal pain non-radiating. Pain is\\n\\nof present illness:\\n\\ndescribed as gnawing and burning, intermitent lasting 1-2\\n\\nhours, and gotten progressively worse. Antacids used to\\n\\nalleviate pain but not anymore; nothing exhacerbates pain.\\n\\nPain unrelated to daytime or to meals. Patient denies\\n\\nconstipation or diarrhea. Patient denies blood in stool but\\n\\nhave noticed them darker. Patient also reports nausea.\\n\\nDenies recent illness or fever. He also reports fatigue\\n\\nsince 2 weeks ago and bloating after eating.\\n\\nPatient ID: NARH-36640\\n\\nROS: Negative except for above findings\\n\\nMeds: Motrin once/week. Tums previously.\\n\\nPMHX: Back pain and muscle spasms. No HX of surgery. NKDA.\\n\\nFHX: Uncle has a bleeding ulcer.\\n\\nSocial Hx: Smokes since 15 yo, 1/2-1 PPD. No recent EtOH\\n\\nuse. Denies illicit drug use. works on high elevation\\n\\nconstruction. Fast food diet. Exercises 3-4 times/week but\\n\\nstopped 2 weeks ago.\\n\\nDischarge\\n\\nSome activity restrictions suggested, full course of\\n\\nDischarge Studies Summary:\\n\\nantibiotics, check back with physican in case of relapse,\\n\\nstrict diet\\n\\nVS/3S/Q990-7550/1090001004290\", metadata={'source': 's3://sagemaker-us-east-1-768517646540/llm/sample/page-1.txt'})]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658eca5f-7e36-4372-813d-6f2c088fc248",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Using HuggingFace FLAN-T5 XL SageMaker endpoint\n",
    "\n",
    "Now we have our Vector DB loaded with the chunks of the document. Now all is left is to take a question from the user, perform similarity search on the Vector DB and then give the model the context and the prompt and wait for it to answer the question. But before that let's define a custom QA chain with the same SageMaker endpoint but a slightly different prompt template since we want the model to answer question from the text rather than generate questions. We won't do a detailed prompt engineering as before but rather use a simple prompt in this case, but the previous method may also be utilized to craft a more robust QA prompt. We use LangChain's `PromptTemplate` to craft the prompt this time -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc2f09f-f6e2-442d-83fc-8b82467d361c",
   "metadata": {},
   "source": [
    "Let's first set the payload parameters of (output) text generation. When invoking the endpoint, our JSON payload can include any desired inference parameters that help control the length, sampling strategy, and output token sequence restrictions. \n",
    "\n",
    "You may refer to this [documentation](https://huggingface.co/docs/transformers/main_classes/text_generation#transformers.GenerationConfig) by HuggingFace for detailed explanation on generation parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9c094f65-2b38-4f58-9791-67a4c44204f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "FLAN_T5_PARAMETERS = {\n",
    "    \"temperature\": 0.97,           # the value used to modulate the next token probabilities.\n",
    "    \"max_length\": 100,             # restrict the length of the generated text.\n",
    "    \"num_return_sequences\": 5,     # number of output sequences returned.\n",
    "    \"top_k\": 50,                   # in each step of text generation, sample from only the top_k most likely words.\n",
    "    \"top_p\": 0.95,                 # in each step of text generation, sample from the smallest possible set of words with cumulative probability top_p.\n",
    "    \"do_sample\": True              # whether or not to use sampling; use greedy decoding otherwise.\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "31f099d4-2ee6-4199-8339-dfaca37927d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain import SagemakerEndpoint\n",
    "from langchain.llms.sagemaker_endpoint import LLMContentHandler\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "import json\n",
    "from typing import Dict\n",
    "\n",
    "# Define a handler class to transform input from LLM to a format that SageMaker endpoint expects.\n",
    "class QAContentHandler(LLMContentHandler):\n",
    "    content_type = \"application/json\"\n",
    "    accepts = \"application/json\"\n",
    "\n",
    "    \n",
    "    def transform_input(self, prompt: str, model_kwargs: Dict) -> bytes:\n",
    "        input_str = json.dumps({\"inputs\": prompt, \"parameters\": model_kwargs})\n",
    "        return input_str.encode(\"utf-8\")\n",
    "\n",
    "    def transform_output(self, output: bytes) -> str:\n",
    "        response_json = json.loads(output.read().decode(\"utf-8\"))\n",
    "        return response_json[0][\"generated_text\"]\n",
    "    \n",
    "\n",
    "\n",
    "qa_content_handler = QAContentHandler()\n",
    "\n",
    "prompt_template=\"\"\"Given the following text from a document, answer the question to the best of your abilities. Answer only from the provided document,, if you do not know the answer \n",
    "just say you don't know. DO NOT make up an answer.\n",
    "\n",
    "Document: {context}\n",
    "Question: {input_query}\n",
    "\"\"\"\n",
    "\n",
    "prompt=PromptTemplate(input_variables=[\"input_query\", \"context\"], \n",
    "                                               template=prompt_template)\n",
    "llm = SagemakerEndpoint(\n",
    "        endpoint_name=\"huggingface-pytorch-tgi-inference-2023-12-10-19-12-31-309\", # replace with your endpoint name if needed\n",
    "        region_name=region,\n",
    "        model_kwargs=FLAN_T5_PARAMETERS,\n",
    "        content_handler=qa_content_handler)\n",
    "\n",
    "qa_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5018ff18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "question=\"What is the patient's name?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acccba52-47db-4e26-95e7-ab7f6f034f9f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Common sense reasoning / natural language inference\n",
    "\n",
    "Perform a similarity search on the document with `k=3` which means it will return the top-3 chunks of text that are relevant to the question asked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d12d790d-d490-4a57-8b38-8386421aa193",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Not a Memorial Hospital\\n\\nOf Collier\\n\\nReg: PN/S/11011, Non-Profit\\n\\nContact: (999)-(888)-(1234)\\n\\nPhysician Hospital Discharge Summary\\n\\nProvider: Mateo Jackson, Phd\\n\\nProvider's Pt ID: 00988277891\\n\\nPatient Gender: Male\\n\\nPatient: John Doe\\n\\nAttachment Control Number: XA/7B/00338763\\n\\nVisit (Encounter)\\n\\nAdmitted: 07-Sep-2020\\n\\nDischarged: 08-Sep-2020\\n\\nDischarged to: Home with support services\\n\\nAssessment\\n\\n35 yo M c/o stomach problems since 2 montsh ago.\\n\\nPatient\\n\\nReported Symptoms / History\\n\\nreports epigastric abdominal pain non-radiating.\\n\\nPatient denies\\n\\nconstipation or diarrhea.\\n\\nPatient denies blood in stool but\\n\\nhave noticed them darker.\\n\\nPatient also reports nausea.\\n\\nDenies recent illness or fever.\\n\\nHe also reports fatigue\\n\\nsince 2 weeks ago and bloating after eating.\\n\\nPatient ID: NARH-36640\\n\\nROS: Negative except for above findings\\n\\nMeds: Motrin once/week.\\n\\nTums previously.\\n\\nPMHX: Back pain and muscle spasms.\\n\\nNo HX of surgery.\\n\\nNKDA.\\n\\nFHX: Uncle has a bleeding ulcer.\\n\\nSocial Hx: Smokes since 15 yo, 1/2-1 PPD.\\n\\nNo recent EtOH\\n\\nuse.\\n\\nDenies illicit drug use.\\n\\nPMHX: Back pain and muscle spasms.\\n\\nNo HX of surgery.\\n\\nNKDA.\\n\\nFHX: Uncle has a bleeding ulcer.\\n\\nSocial Hx: Smokes since 15 yo, 1/2-1 PPD.\\n\\nNo recent EtOH\\n\\nuse.\\n\\nDenies illicit drug use.\\n\\nworks on high elevation\\n\\nconstruction.\\n\\nFast food diet.\\n\\nExercises 3-4 times/week but\\n\\nstopped 2 weeks ago.\\n\\nDischarge\\n\\nSome activity restrictions suggested, full course of\\n\\nDischarge Studies Summary:\\n\\nantibiotics, check back with physican in case of relapse,\\n\\nstrict diet\\n\\nVS/3S/Q990-7550/1090001004290\""
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_docs = vectordb.similarity_search(question, k=3) #see also : max_marginal_relevance_search_by_vector(query, k=3)\n",
    "context_list = [a.page_content for a in similar_docs]\n",
    "metadata_list = [a.metadata.get('source') for a in similar_docs]\n",
    "context = \"\\n\\n\".join(context_list)\n",
    "context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551eb3f3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Question and answering\n",
    "\n",
    "We can now use the custom QA chain with the SageMaker endpoint to provide an answer to our question, based on the content of the documents as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b80cad0f-3010-47f3-bee6-009b36876bfe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'John Doe'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_chain.run({\n",
    "    'input_query': question,\n",
    "    'context': context\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7fee26-24fe-466c-b277-b5b29bf44060",
   "metadata": {},
   "source": [
    "# Gradio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ba7f46-46e3-44b8-9172-41f1301669e9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Automated chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d5d7a226-eb1b-49ac-a69c-82d8fd448667",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='ANYCOMPANY INC\\n\\nPLAN INFORMATION Plan Name\\n\\nANYCOMPANY, INC\\n\\nName And Address Of Employer\\n\\n123 ANY STREET ANY CITY CA, 92127\\n\\nANYCOMPANY, INC\\n\\nName, Address, And Phone Number\\n\\n123 ANY STREET ANY CITY CA, 92127\\n\\nOf Plan Administrator\\n\\n866-648-0044\\n\\nANYCOMPANY, INC.\\n\\nNamed Fiduciary\\n\\nClaims Appeal Fiduciary For Medical Claims\\n\\nUMR\\n\\n12-34567890\\n\\nEmployer Identification Number Assigned By\\n\\nThe IRS\\n\\nPlan Number Assigned By The Plan\\n\\n511\\n\\nSelf-funded Health and Welfare Plan providing\\n\\nType Of Benefit Plan Provided\\n\\ngroup health benefits.', metadata={'source': 's3://sagemaker-us-east-1-768517646540/llm/sample/page-1.txt'}), Document(page_content='You are a valued Employee of ANYCOMPANY, INC., and Your employer is pleased to sponsor this Plan\\n\\nto provide benefits that can help meet Your health care needs.\\n\\nPlease read this document carefully and\\n\\ncontact Your Human Resources or Personnel office if You have questions or if You have difficulty\\n\\ntranslating this document.\\n\\nANYCOMPANY, INC. is named the Plan Administrator for this Plan.', metadata={'source': 's3://sagemaker-us-east-1-768517646540/llm/sample/page-1.txt'}), Document(page_content='All claim\\n\\npayments and reimbursements are paid out of the general assets of the employer and there is no\\n\\nseparate fund that is used to pay promised benefits.\\n\\nThe Plan is intended to comply with and be governed\\n\\nby the Employee Retirement Income Security Act of 1974 (ERISA) and its amendments.\\n\\nSome of the terms used in this document begin with capital letters, even though such terms normally\\n\\nwould not be capitalized.\\n\\nThese terms have special meaning under the Plan.', metadata={'source': 's3://sagemaker-us-east-1-768517646540/llm/sample/page-1.txt'})]\n"
     ]
    }
   ],
   "source": [
    "similar_docs = vectordb.similarity_search(question, k=3)\n",
    "print(similar_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "522d68da-3e3c-4fba-a332-21000a1ee4b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# let's delete the index, we will create it again\n",
    "ids_to_delete=vectordb.get(where={\"source\":  's3://sagemaker-us-east-1-768517646540/llm/sample/page-1.txt'})['ids']\n",
    "vectordb.delete(ids=ids_to_delete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "092b03a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import S3DirectoryLoader\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import NLTKTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.schema import Document\n",
    "import sagemaker\n",
    "\n",
    "data_bucket = sagemaker.Session().default_bucket()\n",
    "prefix='llm/sample'\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings()\n",
    "loader = S3DirectoryLoader(data_bucket, prefix=prefix)\n",
    "docs = loader.load()\n",
    "text_splitter = NLTKTextSplitter(chunk_size=550)\n",
    "texts = text_splitter.split_documents(docs)\n",
    "vectordb = Chroma.from_documents(texts, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3d96dbdf-c96c-4f39-bda9-466cb91b4417",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> **Question**: Hi AI, I am Bob Doe. How are you? \n",
      "\n",
      "**Answer**: I don't know. \n",
      "\n",
      "-> **Question**: Who is the patient? \n",
      "\n",
      "**Answer**: John Doe \n",
      "\n",
      "-> **Question**: Why was John admitted to the hospital? \n",
      "\n",
      "**Answer**: He has been experiencing stomach problems. \n",
      "\n",
      "-> **Question**: Do you remember my name? \n",
      "\n",
      "**Answer**: I don't know. \n",
      "\n",
      "-> **Question**: What past health issues does John have? \n",
      "\n",
      "**Answer**: Back pain and muscle spasms. No HX of surgery. NKDA. F \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain import SagemakerEndpoint\n",
    "from langchain.llms.sagemaker_endpoint import LLMContentHandler\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "import json\n",
    "from typing import Dict\n",
    "\n",
    "\n",
    "\n",
    "FLAN_T5_PARAMETERS = {\n",
    "    \"temperature\": 0.97,           # the value used to modulate the next token probabilities.\n",
    "    \"max_length\": 100,             # restrict the length of the generated text.\n",
    "    \"num_return_sequences\": 5,     # number of output sequences returned.\n",
    "    \"top_k\": 50,                   # in each step of text generation, sample from only the top_k most likely words.\n",
    "    \"top_p\": 0.95,                 # in each step of text generation, sample from the smallest possible set of words with cumulative probability top_p.\n",
    "    \"do_sample\": True              # whether or not to use sampling; use greedy decoding otherwise.\n",
    "}\n",
    "\n",
    "\n",
    "# Define a handler class to transform input from LLM to a format that SageMaker endpoint expects.\n",
    "class QAContentHandler(LLMContentHandler):\n",
    "    content_type = \"application/json\"\n",
    "    accepts = \"application/json\"\n",
    "\n",
    "    \n",
    "    def transform_input(self, prompt: str, model_kwargs: Dict) -> bytes:\n",
    "        input_str = json.dumps({\"inputs\": prompt, \"parameters\": model_kwargs})\n",
    "        return input_str.encode(\"utf-8\")\n",
    "\n",
    "    def transform_output(self, output: bytes) -> str:\n",
    "        response_json = json.loads(output.read().decode(\"utf-8\"))\n",
    "        return response_json[0][\"generated_text\"]\n",
    "    \n",
    "\n",
    "\n",
    "qa_content_handler = QAContentHandler()\n",
    "\n",
    "\n",
    "\n",
    "def create_prompt_template():\n",
    "    _template = \"\"\"\n",
    "    \n",
    "Given the following chat history and a follow up question, rephrase the follow up question to be a standalone question, in its original language. Skip the preamble and just get to the question.\n",
    "\n",
    "<chat_history>    \n",
    "{chat_history}\n",
    "</chat_history>    \n",
    "<follow_up_question>\n",
    "{question}\n",
    "</follow_up_question>\n",
    "\"\"\"\n",
    "    conversation_prompt = PromptTemplate.from_template(_template)\n",
    "    return conversation_prompt\n",
    "\n",
    "template = \"\"\"\n",
    "\n",
    "Answer the question as truthfully as possible strictly using only the provided text, and if the answer is not contained within the text, say \"I don't know\". Skip any preamble text and reasoning and give just the answer. If the user greets you, just greet them back.\n",
    "\n",
    "<text>\n",
    "{context}\n",
    "{chat_history}\n",
    "</text>\n",
    "\n",
    "<question>\n",
    "{input_query}\n",
    "</question>\n",
    "\n",
    "<answer>\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "prompt=PromptTemplate(input_variables=[\"input_query\", \"context\", \"chat_history\"], \n",
    "                                               template=template)\n",
    "llm = SagemakerEndpoint(\n",
    "        endpoint_name=\"huggingface-pytorch-tgi-inference-2023-12-10-19-12-31-309\", # replace with your endpoint name if needed\n",
    "        region_name=region,\n",
    "        model_kwargs=FLAN_T5_PARAMETERS,\n",
    "        content_handler=qa_content_handler)\n",
    "\n",
    "qa_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt\n",
    ")\n",
    "\n",
    "questions = [     \n",
    "    \"Hi AI, I am Bob Doe. How are you?\",\n",
    "    \"Who is the patient?\",\n",
    "    \"Why was John admitted to the hospital?\",\n",
    "    \"Do you remember my name?\",\n",
    "    \"What past health issues does John have?\",\n",
    "]\n",
    "\n",
    "\n",
    "chat_history = []\n",
    "\n",
    "for question in questions:\n",
    "    similar_docs = vectordb.similarity_search(question, k=3) #see also : max_marginal_relevance_search_by_vector(query, k=3)\n",
    "    context_list = [a.page_content for a in similar_docs]\n",
    "    metadata_list = [a.metadata.get('source') for a in similar_docs]\n",
    "    context = \"\\n\\n\".join(context_list)\n",
    "    result = qa_chain.run({\n",
    "        'input_query': question,\n",
    "        'context': context,\n",
    "        'chat_history': chat_history\n",
    "    })\n",
    "    chat_history.append((question, result[0]))\n",
    "    print(f\"-> **Question**: {question} \\n\")\n",
    "    print(f\"**Answer**: {result} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6a772197-2e94-4045-8037-79645f5bd0b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'RootModel' from 'pydantic' (/opt/conda/lib/python3.10/site-packages/pydantic/__init__.cpython-310-x86_64-linux-gnu.so)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[74], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dict\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgradio\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mgr\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchains\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ConversationalRetrievalChain\n\u001b[1;32m     11\u001b[0m FLAN_T5_PARAMETERS \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0.95\u001b[39m,           \u001b[38;5;66;03m# the value used to modulate the next token probabilities.\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_length\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m150\u001b[39m,             \u001b[38;5;66;03m# restrict the length of the generated text.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdo_sample\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m              \u001b[38;5;66;03m# whether or not to use sampling; use greedy decoding otherwise.\u001b[39;00m\n\u001b[1;32m     18\u001b[0m }\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/gradio/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgradio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_simple_templates\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgradio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomponents\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mcomponents\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mgradio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage_utils\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/gradio/_simple_templates/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msimpledropdown\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SimpleDropdown\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msimpletextbox\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SimpleTextbox\n\u001b[1;32m      4\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSimpleDropdown\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSimpleTextbox\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/gradio/_simple_templates/simpledropdown.py:6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any, Callable\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomponents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FormComponent\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevents\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Events\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mSimpleDropdown\u001b[39;00m(FormComponent):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/gradio/components/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomponents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mannotated_image\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AnnotatedImage\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomponents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maudio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Audio\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomponents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbar_plot\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BarPlot\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/gradio/components/annotated_image.py:11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradio_client\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdocumentation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m document, set_documentation_group\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image \u001b[38;5;28;01mas\u001b[39;00m _Image  \u001b[38;5;66;03m# using _ to minimize namespace pollution\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m processing_utils, utils\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcomponents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Component\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_classes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FileData, GradioModel\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/gradio/processing_utils.py:22\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image, ImageOps, PngImagePlugin\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m wasm_utils\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_classes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FileData, GradioModel, GradioRootModel\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m abspath\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/gradio/data_classes.py:14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfastapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Request\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgradio_client\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m traverse\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpydantic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseModel, RootModel, ValidationError\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping_extensions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Literal\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mPredictBody\u001b[39;00m(BaseModel):\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'RootModel' from 'pydantic' (/opt/conda/lib/python3.10/site-packages/pydantic/__init__.cpython-310-x86_64-linux-gnu.so)"
     ]
    }
   ],
   "source": [
    "from langchain import SagemakerEndpoint\n",
    "from langchain.llms.sagemaker_endpoint import LLMContentHandler\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "import json\n",
    "from typing import Dict\n",
    "import random\n",
    "import gradio as gr\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "FLAN_T5_PARAMETERS = {\n",
    "    \"temperature\": 0.95,           # the value used to modulate the next token probabilities.\n",
    "    \"max_length\": 150,             # restrict the length of the generated text.\n",
    "    \"num_return_sequences\": 5,     # number of output sequences returned.\n",
    "    \"top_k\": 50,                   # in each step of text generation, sample from only the top_k most likely words.\n",
    "    \"top_p\": 0.95,                 # in each step of text generation, sample from the smallest possible set of words with cumulative probability top_p.\n",
    "    \"do_sample\": True              # whether or not to use sampling; use greedy decoding otherwise.\n",
    "}\n",
    "\n",
    "\n",
    "# Define a handler class to transform input from LLM to a format that SageMaker endpoint expects.\n",
    "class QAContentHandler(LLMContentHandler):\n",
    "    content_type = \"application/json\"\n",
    "    accepts = \"application/json\"\n",
    "\n",
    "    \n",
    "    def transform_input(self, prompt: str, model_kwargs: Dict) -> bytes:\n",
    "        input_str = json.dumps({\"inputs\": prompt, \"parameters\": model_kwargs})\n",
    "        return input_str.encode(\"utf-8\")\n",
    "\n",
    "    def transform_output(self, output: bytes) -> str:\n",
    "        response_json = json.loads(output.read().decode(\"utf-8\"))\n",
    "        return response_json[0][\"generated_text\"]\n",
    "    \n",
    "\n",
    "\n",
    "qa_content_handler = QAContentHandler()\n",
    "\n",
    "\n",
    "\n",
    "def create_prompt_template():\n",
    "    _template = \"\"\"\n",
    "    \n",
    "Given the following chat history and a follow up question, rephrase the follow up question to be a standalone question, in its original language. Skip the preamble and just get to the question.\n",
    "\n",
    "<chat_history>    \n",
    "{chat_history}\n",
    "</chat_history>    \n",
    "<follow_up_question>\n",
    "{question}\n",
    "</follow_up_question>\n",
    "\"\"\"\n",
    "    conversation_prompt = PromptTemplate.from_template(_template)\n",
    "    return conversation_prompt\n",
    "\n",
    "template = \"\"\"\n",
    "\n",
    "Answer the question as truthfully as possible strictly using only the provided text, and if the answer is not contained within the text, say \"I don't know\". Skip any preamble text and reasoning and give just the answer. If the user greets you, just greet them back.\n",
    "\n",
    "<text>\n",
    "{context}\n",
    "{chat_history}\n",
    "</text>\n",
    "\n",
    "<question>\n",
    "{input_query}\n",
    "</question>\n",
    "\n",
    "<answer>\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "prompt=PromptTemplate(input_variables=[\"input_query\", \"context\", \"chat_history\"], \n",
    "                                               template=template)\n",
    "                     \n",
    "llm = SagemakerEndpoint(\n",
    "        endpoint_name=\"huggingface-pytorch-tgi-inference-2023-12-10-19-12-31-309\", # replace with your endpoint name if needed\n",
    "        region_name=region,\n",
    "        model_kwargs=FLAN_T5_PARAMETERS,\n",
    "        content_handler=qa_content_handler)\n",
    "\n",
    "qa_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt\n",
    ")\n",
    "\n",
    "questions = [     \n",
    "    \"Hi AI, I am Bob Doe. How are you?\",\n",
    "    \"Who is the employer?\",\n",
    "    \"What is the address of the employer?\",\n",
    "    \"Do you remember my name?\"\n",
    "]\n",
    "\n",
    "\n",
    "chat_history = []\n",
    "\n",
    "\n",
    "def qa_chain_fn(message, history):\n",
    "    result = qa_chain.run({\n",
    "        'input_query': message,\n",
    "        'context': context,\n",
    "        'chat_history': chat_history\n",
    "    })\n",
    "    chat_history.append((question, result[\"answer\"]))\n",
    "    return result['answer'].strip()\n",
    "    \n",
    "gr.ChatInterface(qa_chain_fn).launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f14e7ba-3bde-4f8e-9da2-1dea380bf08d",
   "metadata": {},
   "source": [
    "## Use LangChain to create LLM class for Text extraction and SageMaker endpoint calls\n",
    "\n",
    "---\n",
    "Now that we have deployed our endpoints, it is ready to use and perform Summarization on our document. We will use LangChain to perform inference and we need to first create two LLM Classes using the base LangChain LLM Class. Read more about LangChain LLM Class [here](https://python.langchain.com/en/latest/modules/models/llms.html). Specifically we will create two custom LLM classes\n",
    "\n",
    "1. An LLM class to extract text from our document using Amazon Textract\n",
    "2. An LLM class to be able to make calls to the SageMaker endpoint where our FlanT5 model is deployed\n",
    "\n",
    "The purpose of building these custom LLM classes is to be able to easily use these constructs with LangChain's pre-built or custom chains. Read more about LangChain chains [here](https://python.langchain.com/en/latest/modules/chains.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee84ad2-cd3d-4cbc-af7c-78df8bf84268",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.llms.base import LLM\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from typing import Optional, List\n",
    "from textractcaller.t_call import call_textract, Textract_Features\n",
    "from trp.trp2 import TDocumentSchema\n",
    "from trp.t_pipeline import order_blocks_by_geo_x_y\n",
    "import trp\n",
    "import json\n",
    "\n",
    "class OcrLLM(LLM):    \n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"custom\"\n",
    "    \n",
    "    def _call(self, prompt: str, stop: Optional[List[str]] = None) -> str:\n",
    "        # prompt is the document path\n",
    "        if stop is not None:\n",
    "            raise ValueError(\"stop kwargs are not permitted.\")\n",
    "        j = call_textract(input_document=prompt)\n",
    "        t_doc = TDocumentSchema().load(j)\n",
    "        ordered_doc = order_blocks_by_geo_x_y(t_doc)\n",
    "        trp_doc = trp.Document(TDocumentSchema().dump(ordered_doc))\n",
    "        document = str()\n",
    "        for page in trp_doc.pages:\n",
    "            for line in page.lines:\n",
    "                document = document + \"\\n\" + line.text\n",
    "        return document\n",
    "\n",
    "ocrllm = OcrLLM()\n",
    "ocr_prompt = PromptTemplate(\n",
    "    input_variables=[\"doc_path\"],\n",
    "    template=\"{doc_path}\",\n",
    ")\n",
    "ocr_chain = LLMChain(llm=ocrllm, prompt=ocr_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cf5dd6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain import SagemakerEndpoint\n",
    "from langchain.llms.sagemaker_endpoint import LLMContentHandler\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import load_prompt, PromptTemplate\n",
    "import json\n",
    "\n",
    "class ContentHandler(LLMContentHandler):\n",
    "    content_type = \"application/json\"\n",
    "    accepts = \"application/json\"\n",
    "\n",
    "    def transform_input(self, prompt: str, model_kwargs: dict) -> bytes:\n",
    "        input_str = json.dumps({\"text_inputs\": prompt,  **model_kwargs})\n",
    "        return input_str.encode('utf-8')\n",
    "    \n",
    "    def transform_output(self, output: bytes) -> str:\n",
    "        response_json = json.loads(output.read().decode(\"utf-8\"))\n",
    "        return response_json['generated_texts'][0]\n",
    "\n",
    "content_handler = ContentHandler()\n",
    "prompt_template = \"\"\"Write a short summary for this text using your own words without quoting text directly from the provided text. Make sure to only include full and complete sentences: \n",
    "{document}\"\"\"\n",
    "prompt = PromptTemplate.from_template(prompt_template)\n",
    "\n",
    "llm_chain = LLMChain(\n",
    "    llm=SagemakerEndpoint(\n",
    "        endpoint_name=endpoint_name, # replace with your endpoint name if needed\n",
    "        region_name=region,\n",
    "        model_kwargs={\"temperature\":0.97,\n",
    "                      \"max_length\": 150,\n",
    "                      \"num_return_sequences\": 3,\n",
    "                      \"top_k\": 50,\n",
    "                      \"top_p\": 0.95,\n",
    "                      \"do_sample\": True},\n",
    "        content_handler=content_handler\n",
    "    ),\n",
    "    prompt=prompt\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.g4dn.2xlarge",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
